# big-data-analysis-pyspark
Big Data Processing and Insights using PySpark on COVID-19 Open Data
# Big Data Analysis using PySpark

## Project Overview
This project performs big data processing and analysis on the COVID-19 Open Data dataset using PySpark. 
The goal is to extract meaningful insights from large-scale epidemiological data.

## Dataset
- Source: COVID-19 Open Data
- File used: epidemiology.csv
- Format: CSV

## Technologies Used
- Python
- PySpark
- Google Colab
- GitHub

## Tasks Performed
- Installed and configured PySpark
- Loaded large CSV dataset into Spark DataFrame
- Cleaned and selected relevant columns
- Aggregated cumulative confirmed cases and deaths
- Identified top affected locations
- Derived insights from big data processing

## Key Insights
- Certain locations show significantly higher cumulative confirmed cases.
- Aggregation using PySpark prevents double counting.
- PySpark efficiently handles large datasets for analytics.

## How to Run
1. Open the notebook in Google Colab
2. Install PySpark using `pip install pyspark`
3. Upload `epidemiology.csv`
4. Run all cells sequentially

## Author
Nisarga
